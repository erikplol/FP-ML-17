{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "410b4e78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "410b4e78",
        "outputId": "3bc2706d-87a0-498e-ce7a-f6d77b0ddf59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (4.52.4)\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.7.1)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.1.3)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.10.3)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (1.7.0)\n",
            "Requirement already satisfied: nltk in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (3.9.1)\n",
            "Requirement already satisfied: seaborn in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (0.13.2)\n",
            "Requirement already satisfied: emoji in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (2.14.1)\n",
            "Requirement already satisfied: keras>=2.12 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (3.10.0)\n",
            "Requirement already satisfied: tensorflow>=2.12 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (2.19.0)\n",
            "Requirement already satisfied: keras-nlp>=0.6.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (0.21.1)\n",
            "Requirement already satisfied: plotly in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (6.1.2)\n",
            "Requirement already satisfied: tf_keras in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (2.19.0)\n",
            "Requirement already satisfied: jax in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: keras_tuner in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (1.4.7)\n",
            "Requirement already satisfied: pynvml in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (12.0.0)\n",
            "Requirement already satisfied: langdetect in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (1.0.9)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 1)) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 1)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (4.14.0)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (3.5)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (2025.5.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk->-r requirements.txt (line 8)) (8.2.1)\n",
            "Requirement already satisfied: absl-py in ./.venv/lib/python3.12/site-packages (from keras>=2.12->-r requirements.txt (line 11)) (2.3.0)\n",
            "Requirement already satisfied: rich in ./.venv/lib/python3.12/site-packages (from keras>=2.12->-r requirements.txt (line 11)) (14.0.0)\n",
            "Requirement already satisfied: namex in ./.venv/lib/python3.12/site-packages (from keras>=2.12->-r requirements.txt (line 11)) (0.1.0)\n",
            "Requirement already satisfied: h5py in ./.venv/lib/python3.12/site-packages (from keras>=2.12->-r requirements.txt (line 11)) (3.14.0)\n",
            "Requirement already satisfied: optree in ./.venv/lib/python3.12/site-packages (from keras>=2.12->-r requirements.txt (line 11)) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in ./.venv/lib/python3.12/site-packages (from keras>=2.12->-r requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (5.29.5)\n",
            "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (1.73.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in ./.venv/lib/python3.12/site-packages (from tensorflow>=2.12->-r requirements.txt (line 12)) (2.19.0)\n",
            "Requirement already satisfied: keras-hub==0.21.1 in ./.venv/lib/python3.12/site-packages (from keras-nlp>=0.6.0->-r requirements.txt (line 13)) (0.21.1)\n",
            "Requirement already satisfied: kagglehub in ./.venv/lib/python3.12/site-packages (from keras-hub==0.21.1->keras-nlp>=0.6.0->-r requirements.txt (line 13)) (0.3.12)\n",
            "Requirement already satisfied: tensorflow-text in ./.venv/lib/python3.12/site-packages (from keras-hub==0.21.1->keras-nlp>=0.6.0->-r requirements.txt (line 13)) (2.19.0)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in ./.venv/lib/python3.12/site-packages (from plotly->-r requirements.txt (line 14)) (1.42.0)\n",
            "Requirement already satisfied: jaxlib<=0.6.1,>=0.6.1 in ./.venv/lib/python3.12/site-packages (from jax->-r requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: kt-legacy in ./.venv/lib/python3.12/site-packages (from keras_tuner->-r requirements.txt (line 17)) (1.0.5)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in ./.venv/lib/python3.12/site-packages (from pynvml->-r requirements.txt (line 18)) (12.575.51)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow>=2.12->-r requirements.txt (line 12)) (0.45.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers->-r requirements.txt (line 1)) (1.1.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow>=2.12->-r requirements.txt (line 12)) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow>=2.12->-r requirements.txt (line 12)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow>=2.12->-r requirements.txt (line 12)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=2.12->-r requirements.txt (line 11)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich->keras>=2.12->-r requirements.txt (line 11)) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.12->-r requirements.txt (line 11)) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cb3e46ef",
      "metadata": {
        "id": "cb3e46ef"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5b904488",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b904488",
        "outputId": "5d8277f8-046d-41b5-95e5-1f4be32e491f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-15 17:12:54.381868: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749982374.418336   33774 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749982374.429660   33774 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1749982374.452143   33774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749982374.452161   33774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749982374.452164   33774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749982374.452166   33774 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-15 17:12:54.459161: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/barun/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "import re\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from langdetect import detect\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5857c233",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5857c233",
        "outputId": "6e157f39-751c-44ee-93aa-5bb6c36ab2df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_tuner in ./.venv/lib/python3.12/site-packages (1.4.7)\n",
            "Requirement already satisfied: keras in ./.venv/lib/python3.12/site-packages (from keras_tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from keras_tuner) (25.0)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from keras_tuner) (2.32.4)\n",
            "Requirement already satisfied: kt-legacy in ./.venv/lib/python3.12/site-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in ./.venv/lib/python3.12/site-packages (from keras->keras_tuner) (2.3.0)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from keras->keras_tuner) (2.1.3)\n",
            "Requirement already satisfied: rich in ./.venv/lib/python3.12/site-packages (from keras->keras_tuner) (14.0.0)\n",
            "Requirement already satisfied: namex in ./.venv/lib/python3.12/site-packages (from keras->keras_tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in ./.venv/lib/python3.12/site-packages (from keras->keras_tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in ./.venv/lib/python3.12/site-packages (from keras->keras_tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in ./.venv/lib/python3.12/site-packages (from keras->keras_tuner) (0.5.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->keras_tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->keras_tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->keras_tuner) (2025.4.26)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in ./.venv/lib/python3.12/site-packages (from optree->keras->keras_tuner) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich->keras->keras_tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ZOXasr0h9geC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOXasr0h9geC",
        "outputId": "9b20efe7-95a2-48ce-aae7-419549783ce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in ./.venv/lib/python3.12/site-packages (2.14.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6a496794",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6a496794",
        "outputId": "45525395-0280-41f4-9df9-18305ab63413"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>❤️</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I wish there was Julie and the phantoms season 2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I can't stop watching Netflix... really enjoye...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Love it so much</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>best app ever</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  score  thumbsUpCount\n",
              "0                                                 ❤️      5              0\n",
              "1   I wish there was Julie and the phantoms season 2      4              0\n",
              "2  I can't stop watching Netflix... really enjoye...      5              0\n",
              "3                                    Love it so much      5              0\n",
              "4                                      best app ever      5              0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "netflix_reviews_df = pd.read_csv('netflix_reviews.csv')\n",
        "netflix_reviews_df.drop(columns = ['reviewId','userName','reviewCreatedVersion','at','appVersion'],inplace = True)\n",
        "netflix_reviews_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8bab7eb",
      "metadata": {
        "id": "d8bab7eb"
      },
      "source": [
        "<h3>Data Processing</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "165b5b59",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect language of the text\n",
        "def detect_lang(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except:\n",
        "        return 'error'\n",
        "netflix_reviews_df['language'] = (\n",
        "    netflix_reviews_df['content'].astype(str).apply(detect_lang)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1383e24c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I wish there was Julie and the phantoms season 2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I can't stop watching Netflix... really enjoye...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Love it so much</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's has experienced sublime quality to watch ...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this apps is so entertainment me.good job!</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  score  thumbsUpCount  \\\n",
              "0   I wish there was Julie and the phantoms season 2      4              0   \n",
              "1  I can't stop watching Netflix... really enjoye...      5              0   \n",
              "2                                    Love it so much      5              0   \n",
              "3  It's has experienced sublime quality to watch ...      5              0   \n",
              "4         this apps is so entertainment me.good job!      5              0   \n",
              "\n",
              "  language  \n",
              "0       en  \n",
              "1       en  \n",
              "2       en  \n",
              "3       en  \n",
              "4       en  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter out non-English reviews\n",
        "df = netflix_reviews_df[netflix_reviews_df['language'] == 'en']\n",
        "\n",
        "# Reset index after filtering\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ed7b1da5",
      "metadata": {
        "id": "ed7b1da5"
      },
      "outputs": [],
      "source": [
        "import emoji\n",
        "def de_emojize_text(text):\n",
        "    for x in text: # If a text contains an emoji, convert that emoji into its english name\n",
        "        if emoji.is_emoji(x):\n",
        "            demojized = emoji.demojize(x).split(\"_\")\n",
        "            demojized_string = \" \".join(demojized)\n",
        "            text = text.replace(x, demojized_string)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c5bf0400",
      "metadata": {
        "id": "c5bf0400"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()  # lowercase\n",
        "    text = re.sub(r'<.*?>', '', text)  # remove HTML tags\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
        "    text = re.sub(r'\\d+', '', text)  # remove numbers\n",
        "    return text\n",
        "\n",
        "# Apply Function\n",
        "netflix_reviews_df['cleaned_content'] = netflix_reviews_df['content'].astype(str).apply(de_emojize_text).apply(preprocess_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c2fa87",
      "metadata": {
        "id": "29c2fa87"
      },
      "source": [
        "<h3>Feature Extraction</h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1ef56bf5",
      "metadata": {
        "id": "1ef56bf5"
      },
      "outputs": [],
      "source": [
        "# Initialize the TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Fit and transform the cleaned text data\n",
        "X = vectorizer.fit_transform(netflix_reviews_df['cleaned_content'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23c627dc",
      "metadata": {
        "id": "23c627dc"
      },
      "source": [
        "<h3>Sentiment Analysis Model</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "df665e9c",
      "metadata": {
        "id": "df665e9c"
      },
      "outputs": [],
      "source": [
        "def score_to_sentiment(score):\n",
        "    if score <= 2:\n",
        "        return 'negative'\n",
        "    elif score == 3:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        return 'positive'\n",
        "\n",
        "# Apply function\n",
        "netflix_reviews_df['sentiment'] = netflix_reviews_df['score'].apply(score_to_sentiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0bb0d0d",
      "metadata": {
        "id": "d0bb0d0d"
      },
      "source": [
        "<h3>Tokenize and Pad Sequences</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7187d3d6",
      "metadata": {
        "id": "7187d3d6"
      },
      "outputs": [],
      "source": [
        "max_len = 100  # Max number of words in a sequence\n",
        "max_features = 20000\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(netflix_reviews_df['cleaned_content'])\n",
        "sequences = tokenizer.texts_to_sequences(netflix_reviews_df['cleaned_content'])\n",
        "\n",
        "# Pad the sequences\n",
        "X = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Convert sentiments to numerical labels\n",
        "sentiment_label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "y = netflix_reviews_df['sentiment'].map(sentiment_label_map).values\n",
        "\n",
        "# Split the data into training, testing, valid sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X,\n",
        "                                                      y,\n",
        "                                                      test_size=0.1,\n",
        "                                                      random_state=101)\n",
        "\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_valid,\n",
        "                                                    y_valid,\n",
        "                                                    test_size=0.5,\n",
        "                                                    random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d892680f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d892680f",
        "outputId": "9c74604d-e799-4339-e2d4-f279fda51020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n",
            "Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "print(\"Physical devices:\", tf.config.list_physical_devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "395cad90",
      "metadata": {
        "id": "395cad90"
      },
      "source": [
        "<h3>Build and Train the LSTM Model</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "HWTI3G6Pogd-",
      "metadata": {
        "id": "HWTI3G6Pogd-"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pynvml\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "class TrainingMonitor(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        try:\n",
        "            pynvml.nvmlInit()\n",
        "            self.handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "            print(\"NVML berhasil diinisialisasi untuk monitoring GPU.\")\n",
        "        except Exception as e:\n",
        "            self.handle = None\n",
        "            print(f\"Tidak dapat menginisialisasi NVML: {e}. Monitoring GPU tidak akan tersedia.\")\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch_start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        epoch_time = time.time() - self.epoch_start_time\n",
        "        print(f\"Epoch {epoch + 1} selesai dalam {epoch_time:.2f} detik.\")\n",
        "        if self.handle:\n",
        "            try:\n",
        "                mem_info = pynvml.nvmlDeviceGetMemoryInfo(self.handle)\n",
        "                util = pynvml.nvmlDeviceGetUtilizationRates(self.handle)\n",
        "                print(f\"  - Penggunaan VRAM GPU: {mem_info.used / 1024**2:.2f}MB / {mem_info.total / 1024**2:.2f}MB\")\n",
        "                print(f\"  - Utilisasi GPU: {util.gpu}%\")\n",
        "            except Exception as e:\n",
        "                print(f\"  - Tidak dapat mengambil info GPU: {e}\")\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.handle:\n",
        "            pynvml.nvmlShutdown()\n",
        "            print(\"NVML ditutup.\")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "RUiExCS8nLQ8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUiExCS8nLQ8",
        "outputId": "75218922-4879-4937-b1cc-7953f3e304e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from my_dir/sentiment_analysis_tuning/tuner0.json\n",
            "\n",
            "Hyperparameter terbaik ditemukan:\n",
            "  Dimensi Embedding: 160\n",
            "  Unit LSTM: 192\n",
            "  Tingkat Dropout: 0.5\n",
            "  Learning Rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1749983384.590952   33774 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4599 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pynvml\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "import keras_tuner as kt    \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "class TrainingMonitor(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        try:\n",
        "            pynvml.nvmlInit()\n",
        "            self.handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "            print(\"NVML berhasil diinisialisasi untuk monitoring GPU.\")\n",
        "        except Exception as e:\n",
        "            self.handle = None\n",
        "            print(f\"Tidak dapat menginisialisasi NVML: {e}. Monitoring GPU tidak akan tersedia.\")\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch_start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        epoch_time = time.time() - self.epoch_start_time\n",
        "        print(f\"Epoch {epoch + 1} selesai dalam {epoch_time:.2f} detik.\")\n",
        "        if self.handle:\n",
        "            try:\n",
        "                mem_info = pynvml.nvmlDeviceGetMemoryInfo(self.handle)\n",
        "                util = pynvml.nvmlDeviceGetUtilizationRates(self.handle)\n",
        "                print(f\"  - Penggunaan VRAM GPU: {mem_info.used / 1024**2:.2f}MB / {mem_info.total / 124**2:.2f}MB\")\n",
        "                print(f\"  - Utilisasi GPU: {util.gpu}%\")\n",
        "            except Exception as e:\n",
        "                print(f\"  - Tidak dapat mengambil info GPU: {e}\")\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.handle:\n",
        "            pynvml.nvmlShutdown()\n",
        "            print(\"NVML ditutup.\")\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    hp_embedding_dim = hp.Int('embedding_dim', min_value=32, max_value=256, step=32)\n",
        "    model.add(Embedding(input_dim=max_features, output_dim=hp_embedding_dim, input_length=max_len))\n",
        "\n",
        "    hp_lstm_units = hp.Int('lstm_units', min_value=32, max_value=256, step=32)\n",
        "    model.add(LSTM(units=hp_lstm_units, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "    hp_dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n",
        "    model.add(Dropout(hp_dropout_rate))\n",
        "\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=hp_learning_rate),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='sentiment_analysis_tuning',\n",
        "    overwrite=False\n",
        ")\n",
        "\n",
        "callbacks_for_tuning = [\n",
        "    TrainingMonitor(),\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=2,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "]\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=5, validation_data=(X_valid, y_valid), callbacks=callbacks_for_tuning, batch_size=32)\n",
        "\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\\nHyperparameter terbaik ditemukan:\")\n",
        "print(f\"  Dimensi Embedding: {best_hps.get('embedding_dim')}\")\n",
        "print(f\"  Unit LSTM: {best_hps.get('lstm_units')}\")\n",
        "print(f\"  Tingkat Dropout: {best_hps.get('dropout_rate')}\")\n",
        "print(f\"  Learning Rate: {best_hps.get('learning_rate')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "35c451af",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/barun/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "2025-06-15 17:04:46.160658: W external/local_xla/xla/service/gpu/llvm_gpu_backend/default/nvptx_libdevice_path.cc:40] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
            "Searched for CUDA in the following directories:\n",
            "  ./cuda_sdk_lib\n",
            "  ipykernel_launcher.runfiles/cuda_nvcc\n",
            "  ipykern/cuda_nvcc\n",
            "  \n",
            "  /usr/local/cuda\n",
            "  /opt/cuda\n",
            "  /home/barun/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
            "  /home/barun/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
            "  /home/barun/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../cuda\n",
            "  /home/barun/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../../../..\n",
            "  /home/barun/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../../../../..\n",
            "  .\n",
            "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
            "/home/barun/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m all_best_trial_models = \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m save_dir_all_trials = os.path.join(tuner.directory, tuner.project_name, \u001b[33m\"\u001b[39m\u001b[33mall_best_trial_models\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m os.makedirs(save_dir_all_trials, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:400\u001b[39m, in \u001b[36mTuner.get_best_models\u001b[39m\u001b[34m(self, num_models)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[32m    383\u001b[39m \n\u001b[32m    384\u001b[39m \u001b[33;03mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m \u001b[33;03m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[32m    398\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    399\u001b[39m \u001b[38;5;66;03m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:366\u001b[39m, in \u001b[36mBaseTuner.get_best_models\u001b[39m\u001b[34m(self, num_models)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[32m    352\u001b[39m \n\u001b[32m    353\u001b[39m \u001b[33;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    363\u001b[39m \u001b[33;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    365\u001b[39m best_trials = \u001b[38;5;28mself\u001b[39m.oracle.get_best_trials(num_models)\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m models = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:320\u001b[39m, in \u001b[36mTuner.load_model\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     \u001b[38;5;66;03m# Build model to create the weights.\u001b[39;00m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m backend.config.multi_backend() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model.built:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:164\u001b[39m, in \u001b[36mTuner._try_build\u001b[39m\u001b[34m(self, hp)\u001b[39m\n\u001b[32m    161\u001b[39m keras.backend.clear_session()\n\u001b[32m    162\u001b[39m gc.collect()\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_hypermodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Stop if `build()` does not return a valid model.\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, keras.models.Model):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:155\u001b[39m, in \u001b[36mTuner._build_hypermodel\u001b[39m\u001b[34m(self, hp)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_build_hypermodel\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp):\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m maybe_distribute(\u001b[38;5;28mself\u001b[39m.distribution_strategy):\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m         \u001b[38;5;28mself\u001b[39m._override_compile_args(model)\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mbuild_model\u001b[39m\u001b[34m(hp)\u001b[39m\n\u001b[32m     49\u001b[39m model.add(Embedding(input_dim=max_features, output_dim=hp_embedding_dim, input_length=max_len))\n\u001b[32m     51\u001b[39m hp_lstm_units = hp.Int(\u001b[33m'\u001b[39m\u001b[33mlstm_units\u001b[39m\u001b[33m'\u001b[39m, min_value=\u001b[32m32\u001b[39m, max_value=\u001b[32m256\u001b[39m, step=\u001b[32m32\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m model.add(\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhp_lstm_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurrent_dropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     54\u001b[39m hp_dropout_rate = hp.Float(\u001b[33m'\u001b[39m\u001b[33mdropout_rate\u001b[39m\u001b[33m'\u001b[39m, min_value=\u001b[32m0.1\u001b[39m, max_value=\u001b[32m0.5\u001b[39m, step=\u001b[32m0.1\u001b[39m)\n\u001b[32m     55\u001b[39m model.add(Dropout(hp_dropout_rate))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/lstm.py:476\u001b[39m, in \u001b[36mLSTM.__init__\u001b[39m\u001b[34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, seed, return_sequences, return_state, go_backwards, stateful, unroll, use_cudnn, **kwargs)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    449\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    450\u001b[39m     units,\n\u001b[32m   (...)\u001b[39m\u001b[32m    474\u001b[39m     **kwargs,\n\u001b[32m    475\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     cell = \u001b[43mLSTMCell\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrecurrent_activation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecurrent_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43munit_forget_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43munit_forget_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrecurrent_initializer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecurrent_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias_initializer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkernel_regularizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkernel_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrecurrent_regularizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecurrent_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias_regularizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkernel_constraint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkernel_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrecurrent_constraint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecurrent_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias_constraint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrecurrent_dropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecurrent_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrainable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlstm_cell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimplementation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimplementation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    500\u001b[39m         cell,\n\u001b[32m    501\u001b[39m         return_sequences=return_sequences,\n\u001b[32m   (...)\u001b[39m\u001b[32m    507\u001b[39m         **kwargs,\n\u001b[32m    508\u001b[39m     )\n\u001b[32m    509\u001b[39m     \u001b[38;5;28mself\u001b[39m.input_spec = InputSpec(ndim=\u001b[32m3\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/lstm.py:141\u001b[39m, in \u001b[36mLSTMCell.__init__\u001b[39m\u001b[34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, seed, **kwargs)\u001b[39m\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m.dropout_mask_count = \u001b[32m4\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28mself\u001b[39m.seed = seed\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m \u001b[38;5;28mself\u001b[39m.seed_generator = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSeedGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;28mself\u001b[39m.unit_forget_bias = unit_forget_bias\n\u001b[32m    144\u001b[39m \u001b[38;5;28mself\u001b[39m.state_size = [\u001b[38;5;28mself\u001b[39m.units, \u001b[38;5;28mself\u001b[39m.units]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras/src/random/seed_generator.py:87\u001b[39m, in \u001b[36mSeedGenerator.__init__\u001b[39m\u001b[34m(self, seed, name, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backend.convert_to_tensor([seed, \u001b[32m0\u001b[39m], dtype=dtype)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backend.name_scope(\u001b[38;5;28mself\u001b[39m.name, caller=\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28mself\u001b[39m.state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom_seed_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed_generator_state\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras/src/backend/common/variables.py:206\u001b[39m, in \u001b[36mVariable.__init__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(initializer):\n\u001b[32m    205\u001b[39m     \u001b[38;5;28mself\u001b[39m._shape = \u001b[38;5;28mself\u001b[39m._validate_shape(shape)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_with_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28mself\u001b[39m._initialize(initializer)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:52\u001b[39m, in \u001b[36mVariable._initialize_with_initializer\u001b[39m\u001b[34m(self, initializer)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_initialize_with_initializer\u001b[39m(\u001b[38;5;28mself\u001b[39m, initializer):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:42\u001b[39m, in \u001b[36mVariable._initialize\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = value\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_aggregation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_synchronization\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msynchronization\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/ops/variables.py:198\u001b[39m, in \u001b[36mVariableMetaclass.__call__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;129m@traceback_utils\u001b[39m.filter_traceback\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args, **kwargs):\n\u001b[32m    197\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_variable_call\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m._variable_call):\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     variable_call = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m variable_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    200\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m variable_call\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/ops/variables.py:1230\u001b[39m, in \u001b[36mVariable._variable_call\u001b[39m\u001b[34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape, experimental_enable_variable_lifting, **kwargs)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m aggregation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1229\u001b[39m   aggregation = VariableAggregation.NONE\n\u001b[32m-> \u001b[39m\u001b[32m1230\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprevious_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m=\u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/ops/variables.py:1223\u001b[39m, in \u001b[36mVariable._variable_call.<locals>.<lambda>\u001b[39m\u001b[34m(**kws)\u001b[39m\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Variable:\n\u001b[32m   1222\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1223\u001b[39m previous_getter = \u001b[38;5;28;01mlambda\u001b[39;00m **kws: \u001b[43mdefault_variable_creator_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, getter \u001b[38;5;129;01min\u001b[39;00m ops.get_default_graph()._variable_creator_stack:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m   1225\u001b[39m   previous_getter = _make_getter(getter, previous_getter)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/ops/variables.py:51\u001b[39m, in \u001b[36mdefault_variable_creator_v2\u001b[39m\u001b[34m(next_creator, **kwds)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_variable_creator_v2\u001b[39m(next_creator=\u001b[38;5;28;01mNone\u001b[39;00m, **kwds):\n\u001b[32m     49\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m resource_variable_ops  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresource_variable_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_variable_creator_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnext_creator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnext_creator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py:359\u001b[39m, in \u001b[36mdefault_variable_creator_v2\u001b[39m\u001b[34m(next_creator, **kwargs)\u001b[39m\n\u001b[32m    355\u001b[39m shape = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    356\u001b[39m experimental_enable_variable_lifting = kwargs.get(\n\u001b[32m    357\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mexperimental_enable_variable_lifting\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResourceVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m=\u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/ops/variables.py:201\u001b[39m, in \u001b[36mVariableMetaclass.__call__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m variable_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m variable_call\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mVariableMetaclass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py:1876\u001b[39m, in \u001b[36mResourceVariable.__init__\u001b[39m\u001b[34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape, handle, experimental_enable_variable_lifting)\u001b[39m\n\u001b[32m   1871\u001b[39m   \u001b[38;5;28mself\u001b[39m._init_from_handle(trainable=trainable,\n\u001b[32m   1872\u001b[39m                          shape=shape,\n\u001b[32m   1873\u001b[39m                          dtype=dtype,\n\u001b[32m   1874\u001b[39m                          handle=handle)\n\u001b[32m   1875\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1876\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_from_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1877\u001b[39m \u001b[43m      \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1878\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1879\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcollections\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1880\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m      \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m      \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m      \u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m=\u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m      \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m      \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m      \u001b[49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperimental_enable_variable_lifting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py:2135\u001b[39m, in \u001b[36mResourceVariable._init_from_args\u001b[39m\u001b[34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape, validate_shape, experimental_enable_variable_lifting)\u001b[39m\n\u001b[32m   2133\u001b[39m       cached_value = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2135\u001b[39m   \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43massign_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2136\u001b[39m   is_initialized_op = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2137\u001b[39m   initializer_op = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/mundi/ml/fp/.venv/lib/python3.12/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:149\u001b[39m, in \u001b[36massign_variable_op\u001b[39m\u001b[34m(resource, value, validate_shape, name)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m    148\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAssignVariableOp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalidate_shape\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m      \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m    153\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "all_best_trial_models = tuner.get_best_models(num_models=5)\n",
        "\n",
        "save_dir_all_trials = os.path.join(tuner.directory, tuner.project_name, \"all_best_trial_models\")\n",
        "os.makedirs(save_dir_all_trials, exist_ok=True)\n",
        "\n",
        "for i, model_from_trial in enumerate(all_best_trial_models):\n",
        "    model_path = os.path.join(save_dir_all_trials, f\"best_model_trial_{i:02d}.keras\")\n",
        "    model_from_trial.save(model_path)\n",
        "    print(f\"Model terbaik dari Trial {i+1} disimpan ke: {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fbf1de6",
      "metadata": {
        "id": "3fbf1de6"
      },
      "source": [
        "<h3>Evaluate the Model</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "4713a447",
      "metadata": {
        "id": "4713a447"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/barun/mundi/ml/fp/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step\n",
            "Accuracy  : 0.81\n",
            "Precision : 0.77\n",
            "Recall    : 0.81\n",
            "F1 Score  : 0.78\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load model\n",
        "model = tf.keras.models.load_model('my_dir/sentiment_analysis_tuning/all_best_trial_models/best_model_trial_02.keras')\n",
        "\n",
        "# Prediksi\n",
        "predictions = model.predict(X_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1) \n",
        "\n",
        "# True labels\n",
        "true_labels = y_test\n",
        "\n",
        "# Evaluasi\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted', zero_division=0)\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted', zero_division=0)\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted', zero_division=0)\n",
        "\n",
        "# Print hasil\n",
        "print(f\"Accuracy  : {round(accuracy, 2)}\")\n",
        "print(f\"Precision : {round(precision, 2)}\")\n",
        "print(f\"Recall    : {round(recall, 2)}\")\n",
        "print(f\"F1 Score  : {round(f1, 2)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4981370,
          "sourceId": 8490711,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30698,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2438.838969,
      "end_time": "2024-05-23T18:53:21.862729",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-05-23T18:12:43.023760",
      "version": "2.5.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
